{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzniOkIbnDkp",
    "outputId": "104483d7-ec9e-489e-d8e4-170bab449632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
      "changed 22 packages in 2s\n",
      "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K3 packages are looking for funding\n",
      "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit scikit-learn pandas numpy sentence-transformers nltk\n",
    "!npm install -g localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vZKRsZd9n5_W"
   },
   "outputs": [],
   "source": [
    "preprocess_code = '''\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Contraction mapping\n",
    "CONTRACTIONS = {\n",
    "    \"don't\": \"do not\", \"can't\": \"cannot\", \"won't\": \"will not\",\n",
    "    \"i'm\": \"i am\", \"it's\": \"it is\", \"you're\": \"you are\",\n",
    "    \"they're\": \"they are\", \"we're\": \"we are\", \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\", \"wasn't\": \"was not\", \"weren't\": \"were not\",\n",
    "    \"doesn't\": \"does not\", \"didn't\": \"did not\", \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\", \"hadn't\": \"had not\", \"couldn't\": \"could not\",\n",
    "    \"wouldn't\": \"would not\", \"shouldn't\": \"should not\", \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\"\n",
    "}\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\\\S+|www\\\\S+|https\\\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\\\S+@\\\\S+\", \"\", text)\n",
    "    for c, f in CONTRACTIONS.items():\n",
    "        text = text.replace(c, f)\n",
    "    text = re.sub(r\"[^a-z\\\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "'''\n",
    "with open(\"preprocessing.py\", \"w\") as f:\n",
    "    f.write(preprocess_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7OFsKlMn-VM",
    "outputId": "e9cf79d6-f890-4796-cc23-fb9145e7bc59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google.colab import files\n",
    "from preprocessing import clean_text  # unified import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "QsBXyY8DoB6n",
    "outputId": "ae681c9e-79de-41aa-faf3-9e29ed7be643"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-85857d29-1e84-48ee-be26-5cd5d344b69b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-85857d29-1e84-48ee-be26-5cd5d344b69b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving amazon_alexa.tsv to amazon_alexa (3).tsv\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(next(iter(uploaded.values()))), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H9eoDUbBorot"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Handle NaN or None values\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # Remove emails\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "\n",
    "    # Expand contractions\n",
    "    contractions = {\n",
    "        \"don't\": \"do not\", \"can't\": \"cannot\", \"won't\": \"will not\",\n",
    "        \"i'm\": \"i am\", \"it's\": \"it is\", \"you're\": \"you are\",\n",
    "        \"they're\": \"they are\", \"we're\": \"we are\", \"isn't\": \"is not\",\n",
    "        \"aren't\": \"are not\", \"wasn't\": \"was not\", \"weren't\": \"were not\",\n",
    "        \"doesn't\": \"does not\", \"didn't\": \"did not\", \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\", \"hadn't\": \"had not\", \"couldn't\": \"could not\",\n",
    "        \"wouldn't\": \"would not\", \"shouldn't\": \"should not\", \"mightn't\": \"might not\",\n",
    "        \"mustn't\": \"must not\"\n",
    "    }\n",
    "    for c, f in contractions.items():\n",
    "        text = text.replace(c, f)\n",
    "\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing safely\n",
    "df[\"verified_reviews\"] = df[\"verified_reviews\"].apply(clean_text)\n",
    "\n",
    "# Filter empty reviews\n",
    "df = df[df[\"verified_reviews\"].str.strip() != \"\"]\n",
    "\n",
    "# Keep only 'positive' and 'negative'\n",
    "df = df[df[\"feedback\"].isin([\"positive\", \"negative\"])]\n",
    "\n",
    "# Map labels and invert as per your code\n",
    "df[\"feedback\"] = df[\"feedback\"].map({\"positive\": 1, \"negative\": 0}).astype(int)\n",
    "y = 1 - df[\"feedback\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b335544d241f422387ce2092681a333e",
      "0ad0fc9a4e9b4c2581268a43cc622f82",
      "da8ff817d26a4e9981f13fd3f758f3d5",
      "0234a601a45f43ada68f35041ed4fa3e",
      "7f7d77d48af648c6b212443c5d1038ed",
      "66620812f110429cb5281e04bbe42152",
      "56c54482b1954735a963a2a8d30d81d0",
      "45e5c28006ad4f96b4b17413d30480f3",
      "beb56c20a2c7419e9e2e6b8e1a393b0e",
      "f8f05d668c8145c980db86b5269def73",
      "ac1526d74404491ab314201b354057ce"
     ]
    },
    "id": "vYY7BMtAoQNc",
    "outputId": "059adee3-80d3-4861-ed71-9b255e183165"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b335544d241f422387ce2092681a333e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_embed = embedder.encode(df[\"verified_reviews\"].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-R24bnxfoTAc",
    "outputId": "3e930bba-4a72-4e7e-c31c-ee3c96ec78e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feedback unique values: []\n",
      "Normalized feedback values: []\n",
      "Generated label_map: {}\n",
      "Samples remaining after cleaning: 0\n",
      "Unique feedback values after mapping: []\n"
     ]
    }
   ],
   "source": [
    "# Inspect raw feedback values before processing\n",
    "print(\"Raw feedback unique values:\", df[\"feedback\"].unique())\n",
    "\n",
    "# Normalize labels to lowercase strings\n",
    "df[\"feedback\"] = df[\"feedback\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Show again after lowercase/strip\n",
    "print(\"Normalized feedback values:\", df[\"feedback\"].unique())\n",
    "\n",
    "# Create label mapping dynamically based on actual dataset contents\n",
    "positive_keywords = [\"positive\", \"pos\", \"1\", \"yes\", \"true\"]\n",
    "negative_keywords = [\"negative\", \"neg\", \"0\", \"no\", \"false\"]\n",
    "\n",
    "label_map = {}\n",
    "for val in df[\"feedback\"].unique():\n",
    "    if any(k in val for k in positive_keywords):\n",
    "        label_map[val] = 1\n",
    "    elif any(k in val for k in negative_keywords):\n",
    "        label_map[val] = 0\n",
    "\n",
    "print(\"Generated label_map:\", label_map)\n",
    "\n",
    "# Apply mapping\n",
    "df[\"feedback\"] = df[\"feedback\"].map(label_map)\n",
    "\n",
    "# Keep only valid rows\n",
    "df = df[df[\"feedback\"].isin([0, 1])]\n",
    "\n",
    "# Fill NaN reviews and clean text\n",
    "df[\"verified_reviews\"] = df[\"verified_reviews\"].fillna(\"\").apply(clean_text)\n",
    "df = df[df[\"verified_reviews\"].str.strip() != \"\"]\n",
    "\n",
    "# Target variable (invert feedback to match original code)\n",
    "y = 1 - df[\"feedback\"]\n",
    "\n",
    "print(f\"Samples remaining after cleaning: {len(df)}\")\n",
    "print(\"Unique feedback values after mapping:\", df[\"feedback\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrL_u5R7oVMH",
    "outputId": "2859045d-ed48-4cf7-cae4-5b077457a6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and embedder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 0️⃣ Remove old files if they exist\n",
    "for file in [\"model.pkl\", \"embedder.pkl\"]:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "# 1️⃣ Load dataset\n",
    "df = pd.read_csv(\"amazon_alexa.tsv\", sep=\"\\t\")\n",
    "\n",
    "# 2️⃣ Simple text cleaning\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"verified_reviews\"] = df[\"verified_reviews\"].fillna(\"\").apply(clean_text)\n",
    "\n",
    "# 3️⃣ Remove empty reviews\n",
    "df = df[df[\"verified_reviews\"].str.strip() != \"\"]\n",
    "\n",
    "# 4️⃣ Define features and labels\n",
    "y = df[\"feedback\"]  # keep original labels\n",
    "\n",
    "# 5️⃣ Encode text to embeddings\n",
    "model_embed = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_embed = model_embed.encode(df[\"verified_reviews\"].tolist())\n",
    "\n",
    "# 6️⃣ Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embed, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 7️⃣ Train model\n",
    "model = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8️⃣ Save model and embedder\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"embedder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_embed, f)\n",
    "\n",
    "# 9️⃣ Reload to verify\n",
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"embedder.pkl\", \"rb\") as f:\n",
    "    model_embed = pickle.load(f)\n",
    "\n",
    "print(\"✅ Model and embedder saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9xo-eJPFqtbb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for file in [\"model.pkl\", \"embedder.pkl\"]:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "CpkecbkWrR4l",
    "outputId": "09035316-1ad1-4874-93a1-5a9772b8b03c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-fa242be7-77dc-4f83-a9b5-26eaa5d4631a\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-fa242be7-77dc-4f83-a9b5-26eaa5d4631a\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving amazon_alexa.tsv to amazon_alexa (7).tsv\n",
      "(3150, 5)\n",
      "   rating       date         variation  \\\n",
      "0       5  31-Jul-18  Charcoal Fabric    \n",
      "1       5  31-Jul-18  Charcoal Fabric    \n",
      "2       4  31-Jul-18    Walnut Finish    \n",
      "3       5  31-Jul-18  Charcoal Fabric    \n",
      "4       5  31-Jul-18  Charcoal Fabric    \n",
      "\n",
      "                                    verified_reviews  feedback  \n",
      "0                                      Love my Echo!         1  \n",
      "1                                          Loved it!         1  \n",
      "2  Sometimes while playing a game, you can answer...         1  \n",
      "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
      "4                                              Music         1  \n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import pandas as pd\n",
    "df_raw = pd.read_csv(\"amazon_alexa.tsv\", sep=\"\\t\")  # specify tab separator\n",
    "print(df_raw.shape)\n",
    "print(df_raw.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxu112KAuN33",
    "outputId": "c52817b0-0396-4b37-f475-a5570b5e0f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.239.120.191"
     ]
    }
   ],
   "source": [
    "!curl https://loca.lt/mytunnelpassword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTGtP-JIocbS",
    "outputId": "2fb810e7-618f-4928-9b89-a771baae2eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0Kyour url is: https://ten-wasps-rest.loca.lt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "app_code = '''\n",
    "import streamlit as st\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "\n",
    "# Simple text cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    with open(\"embedder.pkl\", \"rb\") as f:\n",
    "        embedder = pickle.load(f)\n",
    "    return model, embedder\n",
    "\n",
    "model, embedder = load_model()\n",
    "\n",
    "st.title(\"Amazon Alexa Review Sentiment Analysis\")\n",
    "st.write(\"Predict whether a review is **Positive** or **Negative**.\")\n",
    "\n",
    "user_input = st.text_area(\"Enter your review:\")\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    cleaned = clean_text(user_input)\n",
    "    if cleaned == \"\":\n",
    "        st.warning(\"Please enter valid text.\")\n",
    "    else:\n",
    "        emb = embedder.encode([cleaned])\n",
    "        pred = model.predict(emb)\n",
    "        sentiment = \"Positive\" if pred[0] == 1 else \"Negative\"\n",
    "        st.success(f\"Prediction: **{sentiment}**\")\n",
    "'''\n",
    "\n",
    "with open(\"app.py\", \"w\") as f:\n",
    "    f.write(app_code)\n",
    "\n",
    "# Run Streamlit in background\n",
    "!nohup streamlit run app.py --server.port 8501 &>/tmp/logs.txt &\n",
    "\n",
    "# Expose via localtunnel (no password)\n",
    "!npx localtunnel --port 8501\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0234a601a45f43ada68f35041ed4fa3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8f05d668c8145c980db86b5269def73",
      "placeholder": "​",
      "style": "IPY_MODEL_ac1526d74404491ab314201b354057ce",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "0ad0fc9a4e9b4c2581268a43cc622f82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66620812f110429cb5281e04bbe42152",
      "placeholder": "​",
      "style": "IPY_MODEL_56c54482b1954735a963a2a8d30d81d0",
      "value": "Batches: "
     }
    },
    "45e5c28006ad4f96b4b17413d30480f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "56c54482b1954735a963a2a8d30d81d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66620812f110429cb5281e04bbe42152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f7d77d48af648c6b212443c5d1038ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac1526d74404491ab314201b354057ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b335544d241f422387ce2092681a333e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ad0fc9a4e9b4c2581268a43cc622f82",
       "IPY_MODEL_da8ff817d26a4e9981f13fd3f758f3d5",
       "IPY_MODEL_0234a601a45f43ada68f35041ed4fa3e"
      ],
      "layout": "IPY_MODEL_7f7d77d48af648c6b212443c5d1038ed"
     }
    },
    "beb56c20a2c7419e9e2e6b8e1a393b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da8ff817d26a4e9981f13fd3f758f3d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45e5c28006ad4f96b4b17413d30480f3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_beb56c20a2c7419e9e2e6b8e1a393b0e",
      "value": 0
     }
    },
    "f8f05d668c8145c980db86b5269def73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
